import streamlit as st
import pandas as pd
import numpy as np
from datetime import datetime
from tensorflow.keras.models import load_model
from tensorflow.keras.preprocessing.sequence import pad_sequences
from joblib import load
import plotly.express as px

# åˆå§‹åŒ– session state
if "prediction_data" not in st.session_state:
    st.session_state.prediction_data = None
if "all_columns" not in st.session_state:
    st.session_state.all_columns = []

# æ¨¡å‹èˆ‡ç·¨ç¢¼å™¨è¼‰å…¥
SEQ_LEN = 10
cat_features = ['action_group', 'source', 'medium', 'platform']
num_features = ['staytime', 'has_shared', 'revisit_count']

@st.cache_resource
def load_model_and_encoders():
    model = load_model("lstm_multi_output_model_v2.h5")
    encoders = {col: load(f'encoder_{col}.pkl') for col in cat_features}
    scalers = {col: load(f'scaler_feature_{col}.pkl') for col in num_features}
    return model, encoders, scalers

model, encoders, scalers = load_model_and_encoders()

def safe_label_transform(encoder, value, default=-1):
    try:
        return encoder.transform([value])[0]
    except:
        return default

def safe_scale(scaler, value, default=0.0):
    try:
        return scaler.transform(np.array([[value]])).flatten()[0]
    except:
        return default

# è¡ŒéŠ·ç­–ç•¥æ¨è–¦é‚è¼¯ï¼ˆæ ¹æ“š Top1 è¡Œç‚ºé æ¸¬çµæœï¼‰
def recommend_strategy(action_group):
    if "è©¦ç®—" in action_group:
        return "æ¨æ’­å„ªæƒ åˆ¸"
    elif "å•†å“è³‡è¨Šé " in action_group or "è¨‚è£½ä¿éšªçµ„åˆ" in action_group:
        return "å»ºè­°å±•ç¤ºå…§å®¹"
    elif "é ç´„" in action_group:
        return "æä¾›é ç´„"
    else:
        return "ç­‰å¾…æ›´å¤šè³‡æ–™"

def predict_from_uploaded_csv(df):
    df = df.sort_values(by=["user_pseudo_id", "event_time"])
    results = []

    for user_id, group in df.groupby("user_pseudo_id"):
        last_steps = group.tail(SEQ_LEN)
        pad_len = SEQ_LEN - len(last_steps)

        cat_seqs = []
        for col in cat_features:
            seq = [safe_label_transform(encoders[col], v) for v in last_steps[col]]
            cat_seqs.append(([0] * pad_len) + seq)

        num_seqs = []
        for col in num_features:
            seq = [safe_scale(scalers[col], v) for v in last_steps[col]]
            num_seqs.append(([0.0] * pad_len) + seq)

        X_cat = [np.array(seq).reshape(1, SEQ_LEN) for seq in cat_seqs]
        X_num = np.array(num_seqs).T.reshape(1, SEQ_LEN, len(num_features))

        y_pred_action_group, y_pred_online, y_pred_o2o = model.predict((*X_cat, X_num), verbose=0)

        top5_indices = y_pred_action_group[0].argsort()[-5:][::-1]
        top5_confidences = y_pred_action_group[0][top5_indices]

        inv_action = {i: v for i, v in enumerate(encoders['action_group'].classes_)}
        top5_actions = [inv_action[idx] for idx in top5_indices]

        strategy = recommend_strategy(top5_actions[0])

        result = {
            "user_pseudo_id": user_id,
            "Top1_next_action_group": top5_actions[0],
            "Top1_confidence": round(top5_confidences[0], 4),
            "Online_conversion_prob": round(y_pred_online[0][0], 4),
            "O2O_reservation_prob": round(y_pred_o2o[0][0], 4),
            "Marketing_Strategy": strategy
        }
        for i in range(5):
            result[f"Top{i+1}_next_action_group"] = top5_actions[i]
            result[f"Top{i+1}_confidence"] = round(top5_confidences[i], 4)

        results.append(result)

    return pd.DataFrame(results)

# === UI ä»‹é¢ ===
st.set_page_config(page_title="åœ‹æ³°äººå£½ - ç”¨æˆ¶è¡Œç‚ºé æ¸¬å·¥å…·", layout="centered", initial_sidebar_state="collapsed")
st.title("ğŸ“Š åœ‹æ³°äººå£½ â€“ å¤šå…ƒè¨ªå®¢è¡Œç‚ºé æ¸¬å·¥å…·")
st.markdown("è«‹ä¸Šå‚³åŒ…å«ç”¨æˆ¶è¡Œç‚ºæ­·ç¨‹è³‡æ–™çš„ CSV é€²è¡Œæ¨¡å‹é æ¸¬")

uploaded_file = st.file_uploader("ğŸ“¥ ä¸Šå‚³ CSVï¼ˆéœ€å«æ¬„ä½ï¼šuser_pseudo_id, event_time, action_group, source, medium, platform, staytime, has_shared, revisit_countï¼‰", type=["csv"])

if uploaded_file is not None:
    try:
        user_df = pd.read_csv(uploaded_file)
        st.success(f"âœ… æˆåŠŸè®€å– {len(user_df)} ç­†è³‡æ–™ï¼Œé–‹å§‹æ¨¡å‹é æ¸¬...")
        st.dataframe(user_df.head(10), use_container_width=True)

        df_result = predict_from_uploaded_csv(user_df)
        st.session_state.prediction_data = df_result
        st.session_state.all_columns = df_result.columns.tolist()
        st.success("ğŸ‰ é æ¸¬å®Œæˆï¼")

    except Exception as e:
        st.error(f"âŒ ç™¼ç”ŸéŒ¯èª¤: {e}")

# === é æ¸¬çµæœå±•ç¤ºèˆ‡ä¸‹è¼‰ ===
if st.session_state.prediction_data is not None:
    df = st.session_state.prediction_data
    st.markdown("### ğŸ“‹ æ¨¡å‹é æ¸¬çµæœ")
    st.dataframe(df, use_container_width=True)

    with st.expander("ğŸ”§ é¸æ“‡æ¬„ä½ä¸‹è¼‰çµæœ", expanded=True):
        selected_columns = st.multiselect(
            "è«‹é¸æ“‡è¦è¼¸å‡ºçš„æ¬„ä½ï¼š",
            options=st.session_state.all_columns,
            default=st.session_state.all_columns
        )

    if selected_columns:
        csv = df[selected_columns].to_csv(index=False).encode("utf-8-sig")
        st.download_button("ğŸ“¥ ä¸‹è¼‰çµæœ CSV", data=csv, file_name="prediction_result.csv", mime="text/csv")
    else:
        st.warning("è«‹é¸æ“‡è‡³å°‘ä¸€å€‹æ¬„ä½")

    # è¦–è¦ºåŒ–åœ–è¡¨
    st.markdown("### ğŸ“Š çµ±è¨ˆåœ–è¡¨")

    chart_df = df["Top1_next_action_group"].value_counts().reset_index()
    chart_df.columns = ["action_group", "count"]
    fig1 = px.bar(chart_df, x="action_group", y="count", title="Top1 è¡Œç‚ºåˆ†ä½ˆ")
    st.plotly_chart(fig1, use_container_width=True)

    fig2 = px.histogram(df, x="Top1_confidence", nbins=20, title="Top1 ä¿¡å¿ƒåˆ†æ•¸åˆ†ä½ˆ")
    st.plotly_chart(fig2, use_container_width=True)

    fig3 = px.scatter(df, x="Top1_confidence", y="Online_conversion_prob", title="ä¿¡å¿ƒåˆ†æ•¸ vs ç·šä¸Šè½‰æ›æ©Ÿç‡")
    st.plotly_chart(fig3, use_container_width=True)

    strategy_df = df["Marketing_Strategy"].value_counts().reset_index()
    strategy_df.columns = ["strategy", "count"]
    fig4 = px.pie(strategy_df, names="strategy", values="count", title="å»ºè­°è¡ŒéŠ·ç­–ç•¥æ¯”ä¾‹")
    st.plotly_chart(fig4, use_container_width=True)


# streamlit run app1.py
